{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#Team members: Venkata Sampat(301846000), Harshitha Vallabhaneni(301094795)\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "#Sigmoid func\n",
        "def sigmoid(x):\n",
        "    return 1 / (1 + np.exp(-x))\n",
        "\n",
        "# Derv sigmoid function\n",
        "def sigmoid_derivative(x):\n",
        "    return x * (1 - x)\n",
        "\n",
        "#Given Data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "#Shape of the neural network\n",
        "input_nodes = 2\n",
        "hidden_nodes = 2\n",
        "output_nodes = 1\n",
        "\n",
        "j=0 #To run of our code for 5 different weight sets\n",
        "\n",
        "while (j<5):\n",
        "\n",
        "  #Taking random weights\n",
        "  w_hidden = np.random.uniform(size=(input_nodes, hidden_nodes))\n",
        "  w_output = np.random.uniform(size=(hidden_nodes, output_nodes))\n",
        "\n",
        "  learning_rate = 0.1\n",
        "  epochs = 10000\n",
        "\n",
        "  for epoch in range(epochs):\n",
        "\n",
        "      # Forward propagation\n",
        "      hidden_output = sigmoid(np.dot(X, w_hidden))\n",
        "      output = sigmoid(np.dot(hidden_output, w_output))\n",
        "\n",
        "      error = y - output\n",
        "\n",
        "      # Backward propagation\n",
        "      output_error = error * sigmoid_derivative(output)\n",
        "      hidden_error = np.dot(output_error, w_output.T) * sigmoid_derivative(hidden_output)\n",
        "\n",
        "      # Updating weights\n",
        "      w_output += np.dot(hidden_output.T, output_error) * learning_rate\n",
        "      w_hidden += np.dot(X.T, hidden_error) * learning_rate\n",
        "\n",
        "  print(\"\\nTraining set:\",j+1)\n",
        "\n",
        "  print(\"Initial Weights:\")\n",
        "  print(\"hidden layer weights:\", w_hidden)\n",
        "  print(\"output weight:\", w_output)\n",
        "\n",
        "  print(\"\\nAdjusted Weights:\")\n",
        "  print(\"hidden layer weight:\", w_hidden)\n",
        "  print(\"output weight:\", w_output)\n",
        "\n",
        "  print(\"\\nOutputs for data:\")\n",
        "  print(output)\n",
        "\n",
        "  print(\"\\nLearning Rate:\", learning_rate)\n",
        "  print(\"Squared Error:\", np.sum(error**2) / 2)\n",
        "  print(\"Accuracy:\", np.mean(np.round(output) == y))\n",
        "\n",
        "  j=j+1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V67fzgMPRzUV",
        "outputId": "19ea583e-b4b1-4a57-9678-a7ab0ffaa8a2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Training set: 1\n",
            "Initial Weights:\n",
            "hidden layer weights: [[0.75392889 5.19380816]\n",
            " [0.75463084 5.22435371]]\n",
            "output weight: [[-9.96318223]\n",
            " [ 7.68371441]]\n",
            "\n",
            "Adjusted Weights:\n",
            "hidden layer weight: [[0.75392889 5.19380816]\n",
            " [0.75463084 5.22435371]]\n",
            "output weight: [[-9.96318223]\n",
            " [ 7.68371441]]\n",
            "\n",
            "Outputs for data:\n",
            "[[0.24239383]\n",
            " [0.70383934]\n",
            " [0.70389198]\n",
            " [0.3834944 ]]\n",
            "\n",
            "Learning Rate: 0.1\n",
            "Squared Error: 0.1906069122981796\n",
            "Accuracy: 1.0\n",
            "\n",
            "Training set: 2\n",
            "Initial Weights:\n",
            "hidden layer weights: [[5.79034102 0.80042946]\n",
            " [5.78959691 0.8004202 ]]\n",
            "output weight: [[ 10.27435878]\n",
            " [-13.23407007]]\n",
            "\n",
            "Adjusted Weights:\n",
            "hidden layer weight: [[5.79034102 0.80042946]\n",
            " [5.78959691 0.8004202 ]]\n",
            "output weight: [[ 10.27435878]\n",
            " [-13.23407007]]\n",
            "\n",
            "Outputs for data:\n",
            "[[0.18546328]\n",
            " [0.75223993]\n",
            " [0.75223938]\n",
            " [0.32339252]]\n",
            "\n",
            "Learning Rate: 0.1\n",
            "Squared Error: 0.13087486118956596\n",
            "Accuracy: 1.0\n",
            "\n",
            "Training set: 3\n",
            "Initial Weights:\n",
            "hidden layer weights: [[0.65730372 4.01871049]\n",
            " [0.66884096 4.13357432]]\n",
            "output weight: [[-5.58266367]\n",
            " [ 4.29104272]]\n",
            "\n",
            "Adjusted Weights:\n",
            "hidden layer weight: [[0.65730372 4.01871049]\n",
            " [0.66884096 4.13357432]]\n",
            "output weight: [[-5.58266367]\n",
            " [ 4.29104272]]\n",
            "\n",
            "Outputs for data:\n",
            "[[0.34398215]\n",
            " [0.62988339]\n",
            " [0.63136893]\n",
            " [0.46966606]]\n",
            "\n",
            "Learning Rate: 0.1\n",
            "Squared Error: 0.30589254938328203\n",
            "Accuracy: 1.0\n",
            "\n",
            "Training set: 4\n",
            "Initial Weights:\n",
            "hidden layer weights: [[5.69914106 0.79352524]\n",
            " [5.70344601 0.79358395]]\n",
            "output weight: [[  9.83580484]\n",
            " [-12.68325396]]\n",
            "\n",
            "Adjusted Weights:\n",
            "hidden layer weight: [[5.69914106 0.79352524]\n",
            " [5.70344601 0.79358395]]\n",
            "output weight: [[  9.83580484]\n",
            " [-12.68325396]]\n",
            "\n",
            "Outputs for data:\n",
            "[[0.19409384]\n",
            " [0.7444735 ]\n",
            " [0.74447714]\n",
            " [0.33314857]]\n",
            "\n",
            "Learning Rate: 0.1\n",
            "Squared Error: 0.1396230557695545\n",
            "Accuracy: 1.0\n",
            "\n",
            "Training set: 5\n",
            "Initial Weights:\n",
            "hidden layer weights: [[0.69843485 4.51673799]\n",
            " [0.69722645 4.49344168]]\n",
            "output weight: [[-6.99777874]\n",
            " [ 5.37411449]]\n",
            "\n",
            "Adjusted Weights:\n",
            "hidden layer weight: [[0.69843485 4.51673799]\n",
            " [0.69722645 4.49344168]]\n",
            "output weight: [[-6.99777874]\n",
            " [ 5.37411449]]\n",
            "\n",
            "Outputs for data:\n",
            "[[0.30753949]\n",
            " [0.6554401 ]\n",
            " [0.65532195]\n",
            " [0.44149579]]\n",
            "\n",
            "Learning Rate: 0.1\n",
            "Squared Error: 0.2635117745085105\n",
            "Accuracy: 1.0\n"
          ]
        }
      ]
    }
  ]
}